{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.cautils.notebook import *\n",
    "\n",
    "from transformer_lens.rs.callum2.ioi_and_bos.ioi_functions import get_effective_embedding_2\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    device=\"cpu\",\n",
    "    # refactor_factored_attn_matrices=True,\n",
    ")\n",
    "model.set_use_attn_result(False)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_EE = get_effective_embedding_2(model)[\"W_E (including MLPs)\"]\n",
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_EE_scaled = W_EE / W_EE.std(dim=-1, keepdim=True)\n",
    "W_U_scaled = W_U / W_U.std(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation for the scale factors\n",
    "\n",
    "### QK\n",
    "\n",
    "For keys, we should use the effective embedding divided by its std (because it'll have been layernormed).\n",
    "\n",
    "For queries, I'm not totally sure. I think we should scale it, because we're pretending that the token is predicted in the residual stream as strongly as it could possibly be.\n",
    "\n",
    "### OV\n",
    "\n",
    "Things are a little more suble here. `W_EE_scaled @ W_V @ W_O` gets scaled before we extract logit lens. So we need to find this matrix, find its std deviation, and then divide `W_EE_scaled @ W_V` by this. `W_O @ W_U` is kept as is, because this is meant to represent the logit lens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-13.8703,  -4.8223,  -6.6856,  ...,   9.8913,  -5.1538,  -6.4966],\n",
       "        [ -4.6475,  -8.4365,  -2.8866,  ...,  -0.6939,  -5.3109,  -4.9171],\n",
       "        [-10.0955,  -8.3327, -26.0346,  ...,   9.3406,   4.4333,  -4.9627],\n",
       "        ...,\n",
       "        [  3.1475,   2.1202,  12.1503,  ..., -31.8955,   2.2347,   5.6589],\n",
       "        [  0.0972,   1.8421,  16.0855,  ...,   2.1897, -22.1990,  -0.5207],\n",
       "        [ -0.2282,   1.1538,   3.2172,  ...,  -3.3892,  -5.6115,  -1.7882]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(W_EE_V @ W_U_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_EE_V = W_EE_scaled @ model.W_V[10, 7]\n",
    "W_EE_V_O = W_EE_V @ model.W_O[10, 7]\n",
    "W_EE_V_O_scale = W_EE_V_O.std(dim=-1)\n",
    "W_EE_V = W_EE_V / W_EE_V_O_scale[:, None]\n",
    "\n",
    "W_U_O = (model.W_O[10, 7] @ W_U)\n",
    "\n",
    "W_U_Q = W_U_scaled.T @ model.W_Q[10, 7]\n",
    "\n",
    "W_EE_K = W_EE_scaled @ model.W_K[10, 7]\n",
    "\n",
    "dict_to_store_less = {\n",
    "    \"tokenizer\": model.tokenizer,\n",
    "    \"W_EE_V\": W_EE_V,\n",
    "    \"W_U_O\": W_U_O,\n",
    "    \"W_U_Q\": W_U_Q,\n",
    "    \"W_EE_K\": W_EE_K,\n",
    "    # \"b_Q\": model.b_Q[10, 7],\n",
    "    # \"b_K\": model.b_K[10, 7],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ubuntu/SERI-MATS-2023-Streamlit-pages/transformer_lens/rs/callum2/st_page/media/\"\n",
    "with gzip.open(path + \"OV_QK_circuits_less.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dict_to_store_less, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
